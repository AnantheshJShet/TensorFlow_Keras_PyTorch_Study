{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Image classification using CNN in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow\n",
    "import tensorflow as tf\n",
    "# Import MNIST dataset\n",
    "from tensorflow.examples.tutorials import mnist\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read in MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-efed16007034>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Anaconda\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "data = mnist.input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (images) shape: (55000, 784)\n",
      "Training set (labels) shape: (55000, 10)\n",
      "Test set (images) shape: (10000, 784)\n",
      "Test set (labels) shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of training set\n",
    "print(\"Training set (images) shape: {shape}\".format(shape=data.train.images.shape))\n",
    "print(\"Training set (labels) shape: {shape}\".format(shape=data.train.labels.shape))\n",
    "\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=data.test.images.shape))\n",
    "print(\"Test set (labels) shape: {shape}\".format(shape=data.test.labels.shape))\n",
    "\n",
    "image_hgt = 28\n",
    "image_wid = 28\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    "    0: 'Zero',\n",
    "    1: 'One',\n",
    "    2: 'Two',\n",
    "    3: 'Three',\n",
    "    4: 'Four',\n",
    "    5: 'Five',\n",
    "    6: 'Six',\n",
    "    7: 'Seven',\n",
    "    8: 'Eight',\n",
    "    9: 'Nine'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '(Label: Two)')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display first image in training data\n",
    "plt.subplot(121)\n",
    "img = np.reshape(data.train.images[0], (image_hgt,image_wid))\n",
    "lbl = np.argmax(data.train.labels[0,:])\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[lbl]) + \")\")\n",
    "\n",
    "# Display second image in testing data\n",
    "plt.subplot(122)\n",
    "img = np.reshape(data.test.images[1], (image_hgt,image_wid))\n",
    "lbl = np.argmax(data.test.labels[1,:])\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1) (10000, 28, 28, 1)\n",
      "(55000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Reshape training and testing images\n",
    "train_X = data.train.images.reshape(-1, image_hgt, image_wid, 1) # number of samples, length, width, number of channels\n",
    "test_X = data.test.images.reshape(-1, image_hgt, image_wid, 1) # number of samples, length, width, number of channels\n",
    "print(train_X.shape, test_X.shape)\n",
    "\n",
    "train_Y = data.train.labels\n",
    "test_Y = data.test.labels\n",
    "print(train_Y.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "epochs = 50\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Weights dictionary        \n",
    "weight_dict = {\n",
    "    'filterWC1' : tf.get_variable('FWC1', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'filterWC2' : tf.get_variable('FWC2', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'fullyConnW' : tf.get_variable('FCW', shape=(7*7*64,64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'OutputW' : tf.get_variable('OW', shape=(64,n_classes), initializer=tf.contrib.layers.xavier_initializer())\n",
    "}\n",
    "\n",
    "bias_dict = {\n",
    "    'filterBC1' : tf.get_variable('FBC1', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'filterBC2' : tf.get_variable('FBC2', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'fullyConnB' : tf.get_variable('FCB', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'OutputB' : tf.get_variable('OB', shape=(n_classes), initializer=tf.contrib.layers.xavier_initializer())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def conv2d(inp, filter_weight, filter_bias, strides=1):\n",
    "    inp = tf.nn.conv2d(inp, filter_weight, strides = [1, strides, strides, 1], padding = 'SAME')\n",
    "    inp = tf.nn.bias_add(inp, filter_bias)\n",
    "    return tf.nn.relu(inp)\n",
    "\n",
    "def maxpool2d(inp, ksize=2):\n",
    "    return tf.nn.max_pool(inp, ksize = [1, ksize, ksize, 1], strides = [1, ksize, ksize, 1], padding = 'SAME')\n",
    "    \n",
    "def flatten(inp, size):\n",
    "    return tf.reshape(inp, [-1, size])\n",
    "    \n",
    "def fc(inp, fc_weight, fc_bias):\n",
    "    fc = tf.matmul(inp, fc_weight)\n",
    "    fc = tf.add(fc, fc_bias)\n",
    "    return tf.nn.relu(fc)\n",
    "    \n",
    "def out(inp, out_weight, out_bias):\n",
    "    out = tf.matmul(inp, out_weight)\n",
    "    return tf.add(out, out_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(inp, weight_dict, bias_dict):\n",
    "    # Convolution Layer 1\n",
    "    conv1 = conv2d(inp, weight_dict['filterWC1'], bias_dict['filterBC1'])\n",
    "    conv1 = maxpool2d(conv1, ksize=2)\n",
    "    \n",
    "    # Convolution Layer 2\n",
    "    conv2 = conv2d(conv1, weight_dict['filterWC2'], bias_dict['filterBC2'])\n",
    "    conv2 = maxpool2d(conv2, ksize=2)\n",
    "    \n",
    "    # Flatten the convolution layer output\n",
    "    flatten_layer = flatten(conv2, weight_dict['fullyConnW'].get_shape().as_list()[0])\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    fc1 = fc(flatten_layer, weight_dict['fullyConnW'], bias_dict['fullyConnB'])\n",
    "    \n",
    "    # Output, class prediction\n",
    "    out_layer = out(fc1, weight_dict['OutputW'], bias_dict['OutputB'])\n",
    "    \n",
    "    return out_layer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "x = tf.placeholder(tf.float32, [None, image_hgt, image_wid, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-c6781f5697ab>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "pred = conv_net(x, weight_dict, bias_dict)\n",
    "\n",
    "# Define the Cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you check whether the index of the maximum value of the predicted image \n",
    "# is equal to the actual labelled image and both will be a column vector\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "# Calculate accuracy across all the given images and average them out. \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. TensorFlow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = nan, Training Accuracy = nan\n",
      "Testing Accuracy: 0.87400\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Variable must be initialized before a graph is used for the first time.\n",
    "    sess.run(init)\n",
    "    train_loss_list = []\n",
    "    test_loss_list = []\n",
    "    train_accuracy_list = []\n",
    "    test_accuracy_list = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(len(train_X//batch_size)):\n",
    "            batch_x = train_X[batch*batch_size:min(((batch+1)*batch_size), len(train_X))]\n",
    "            batch_y = train_Y[batch*batch_size:min(((batch+1)*batch_size), len(train_Y))]\n",
    "            \n",
    "            opt = sess.run(optimizer, feed_dict = {x:batch_x, y:batch_y})\n",
    "            train_loss, train_acc = sess.run([cost, accuracy], feed_dict = {x:batch_x, y:batch_y})\n",
    "            \n",
    "        print(\"Epoch \" + str(epoch) + \", Loss = {:.6f}\".format(train_loss) + \", Training Accuracy = {:.5f}\".format(train_acc))\n",
    "        \n",
    "        \n",
    "        # Calclate accuracy for all test images\n",
    "        test_loss, test_acc = sess.run([cost, accuracy], feed_dict = {x:test_X, y:test_Y})\n",
    "        print(\"Testing Accuracy: {:.5f}\".format(test_acc))\n",
    "        \n",
    "        train_loss_list.append(train_loss)\n",
    "        test_loss_list.append(test_loss)\n",
    "        train_accuracy_list.append(train_acc)\n",
    "        test_accuracy_list.append(test_acc)\n",
    "        \n",
    "    summary_writer.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), train_loss, 'b', label='Training Loss')\n",
    "plt.plot(range(epochs), test_loss, 'r', label='Test Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(epochs), train_accuracy, 'b', label='Training Accuracy')\n",
    "plt.plot(range(epochs), test_accuracy, 'r', label='Test Accuracy')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
